{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering main\n",
      "Loading wav files....\n",
      "1\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nicholas/opt/anaconda3/lib/python3.8/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import sys\n",
    "sys.path.append('../speech-accent-recognition/src>')\n",
    "#import importlib\n",
    "#importlib.__import__(getsplit)\n",
    "import getsplit\n",
    "\n",
    "from keras import utils\n",
    "import accuracy\n",
    "import multiprocessing\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import MaxPooling2D, Conv2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "DEBUG = True\n",
    "SILENCE_THRESHOLD = .01\n",
    "RATE = 24000\n",
    "N_MFCC = 13\n",
    "COL_SIZE = 30\n",
    "EPOCHS = 10 #35#250\n",
    "\n",
    "def to_categorical(y):\n",
    "    '''\n",
    "    Converts list of languages into a binary class matrix\n",
    "    :param y (list): list of languages\n",
    "    :return (numpy array): binary class matrix\n",
    "    '''\n",
    "    lang_dict = {}\n",
    "    for index,language in enumerate(set(y)):\n",
    "        lang_dict[language] = index\n",
    "    y = list(map(lambda x: lang_dict[x],y))\n",
    "    return utils.to_categorical(y, len(lang_dict))\n",
    "\n",
    "def get_wav(language_num):\n",
    "    '''\n",
    "    Load wav file from disk and down-samples to RATE\n",
    "    :param language_num (list): list of file names\n",
    "    :return (numpy array): Down-sampled wav file\n",
    "    '''\n",
    "    print(3)\n",
    "    y, sr = librosa.load('/audio/{}.wav'.format(language_num))\n",
    "    print(4)\n",
    "    return(librosa.core.resample(y=y,orig_sr=sr,target_sr=RATE, scale=True))\n",
    "\n",
    "def to_mfcc(wav):\n",
    "    '''\n",
    "    Converts wav file to Mel Frequency Ceptral Coefficients\n",
    "    :param wav (numpy array): Wav form\n",
    "    :return (2d numpy array: MFCC\n",
    "    '''\n",
    "    return(librosa.feature.mfcc(y=wav, sr=RATE, n_mfcc=N_MFCC))\n",
    "\n",
    "def remove_silence(wav, thresh=0.04, chunk=5000):\n",
    "    '''\n",
    "    Searches wav form for segments of silence. If wav form values are lower than 'thresh' for 'chunk' samples, the values will be removed\n",
    "    :param wav (np array): Wav array to be filtered\n",
    "    :return (np array): Wav array with silence removed\n",
    "    '''\n",
    "\n",
    "    tf_list = []\n",
    "    for x in range(len(wav) / chunk):\n",
    "        if (np.any(wav[chunk * x:chunk * (x + 1)] >= thresh) or np.any(wav[chunk * x:chunk * (x + 1)] <= -thresh)):\n",
    "            tf_list.extend([True] * chunk)\n",
    "        else:\n",
    "            tf_list.extend([False] * chunk)\n",
    "\n",
    "    tf_list.extend((len(wav) - len(tf_list)) * [False])\n",
    "    return(wav[tf_list])\n",
    "\n",
    "def normalize_mfcc(mfcc):\n",
    "    '''\n",
    "    Normalize mfcc\n",
    "    :param mfcc:\n",
    "    :return:\n",
    "    '''\n",
    "    mms = MinMaxScaler()\n",
    "    return(mms.fit_transform(np.abs(mfcc)))\n",
    "\n",
    "def make_segments(mfccs,labels):\n",
    "    '''\n",
    "    Makes segments of mfccs and attaches them to the labels\n",
    "    :param mfccs: list of mfccs\n",
    "    :param labels: list of labels\n",
    "    :return (tuple): Segments with labels\n",
    "    '''\n",
    "    segments = []\n",
    "    seg_labels = []\n",
    "    for mfcc,label in zip(mfccs,labels):\n",
    "        for start in range(0, int(mfcc.shape[1] / COL_SIZE)):\n",
    "            segments.append(mfcc[:, start * COL_SIZE:(start + 1) * COL_SIZE])\n",
    "            seg_labels.append(label)\n",
    "    return(segments, seg_labels)\n",
    "\n",
    "def segment_one(mfcc):\n",
    "    '''\n",
    "    Creates segments from on mfcc image. If last segments is not long enough to be length of columns divided by COL_SIZE\n",
    "    :param mfcc (numpy array): MFCC array\n",
    "    :return (numpy array): Segmented MFCC array\n",
    "    '''\n",
    "    segments = []\n",
    "    for start in range(0, int(mfcc.shape[1] / COL_SIZE)):\n",
    "        segments.append(mfcc[:, start * COL_SIZE:(start + 1) * COL_SIZE])\n",
    "    return(np.array(segments))\n",
    "\n",
    "def create_segmented_mfccs(X_train):\n",
    "    '''\n",
    "    Creates segmented MFCCs from X_train\n",
    "    :param X_train: list of MFCCs\n",
    "    :return: segmented mfccs\n",
    "    '''\n",
    "    segmented_mfccs = []\n",
    "    for mfcc in X_train:\n",
    "        segmented_mfccs.append(segment_one(mfcc))\n",
    "    return(segmented_mfccs)\n",
    "\n",
    "\n",
    "def train_model(X_train,y_train,X_validation,y_validation, batch_size=128): #64\n",
    "    '''\n",
    "    Trains 2D convolutional neural network\n",
    "    :param X_train: Numpy array of mfccs\n",
    "    :param y_train: Binary matrix based on labels\n",
    "    :return: Trained model\n",
    "    '''\n",
    "\n",
    "    # Get row, column, and class sizes\n",
    "    rows = X_train[0].shape[0]\n",
    "    cols = X_train[0].shape[1]\n",
    "    val_rows = X_validation[0].shape[0]\n",
    "    val_cols = X_validation[0].shape[1]\n",
    "    num_classes = len(y_train[0])\n",
    "\n",
    "    # input image dimensions to feed into 2D ConvNet Input layer\n",
    "    input_shape = (rows, cols, 1)\n",
    "    X_train = X_train.reshape(X_train.shape[0], rows, cols, 1 )\n",
    "    X_validation = X_validation.reshape(X_validation.shape[0],val_rows,val_cols,1)\n",
    "\n",
    "\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'training samples')\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3,3), activation='relu',\n",
    "                     data_format=\"channels_last\",\n",
    "                     input_shape=input_shape))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64,kernel_size=(3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Stops training if accuracy does not change at least 0.005 over 10 epochs\n",
    "    es = EarlyStopping(monitor='acc', min_delta=.005, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "    # Creates log file for graphical interpretation using TensorBoard\n",
    "    tb = TensorBoard(log_dir='../logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=True,\n",
    "                     write_images=True, embeddings_freq=0, embeddings_layer_names=None,\n",
    "                     embeddings_metadata=None)\n",
    "\n",
    "    # Image shifting\n",
    "    datagen = ImageDataGenerator(width_shift_range=0.05)\n",
    "\n",
    "    # Fit model using ImageDataGenerator\n",
    "    model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=len(X_train) / 32\n",
    "                        , epochs=EPOCHS,\n",
    "                        callbacks=[es,tb], validation_data=(X_validation,y_validation))\n",
    "\n",
    "    return (model)\n",
    "\n",
    "def save_model(model, model_filename):\n",
    "    '''\n",
    "    Save model to file\n",
    "    :param model: Trained model to be saved\n",
    "    :param model_filename: Filename\n",
    "    :return: None\n",
    "    '''\n",
    "    model.save('../models/{}.h5'.format(model_filename))  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "\n",
    "\n",
    "############################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    '''\n",
    "        Console command example:\n",
    "        python trainmodel.py bio_metadata.csv model50\n",
    "        '''\n",
    "\n",
    "    # Load arguments\n",
    "    # print(sys.argv)\n",
    "    file_name = 'data_afr_azer_dan.csv'\n",
    "    model_filename = 'model1.h5'\n",
    "\n",
    "    # Load metadata\n",
    "    df = pd.read_csv(file_name)\n",
    "\n",
    "\n",
    "    # Filter metadata to retrieve only files desired\n",
    "    filtered_df = getsplit.filter_df(df)\n",
    "\n",
    "    # filtered_df = filter_df(df)\n",
    "\n",
    "    # print(filtered_df)\n",
    "\n",
    "    # print(\"filterd df is empty {}\".format(filtered_df))\n",
    "\n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = getsplit.split_people(filtered_df)\n",
    "\n",
    "    # Get statistics\n",
    "    train_count = Counter(y_train)\n",
    "    test_count = Counter(y_test)\n",
    "\n",
    "    print(\"Entering main\")\n",
    "\n",
    "    # import ipdb;\n",
    "    # ipdb.set_trace()\n",
    "\n",
    "\n",
    "    acc_to_beat = test_count.most_common(1)[0][1] / float(np.sum(list(test_count.values())))\n",
    "\n",
    "    # To categorical\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "\n",
    "    # Get resampled wav files using multiprocessing\n",
    "    if DEBUG:\n",
    "        print('Loading wav files....')\n",
    "    pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "    print(1)\n",
    "    X_train = get_wav(X_train)\n",
    "    print(2)\n",
    "    X_test = get_wav(X_test)\n",
    "\n",
    "    # Convert to MFCC\n",
    "    if DEBUG:\n",
    "        print('Converting to MFCC....')\n",
    "    X_train = pool.map(to_mfcc, X_train)\n",
    "    X_test = pool.map(to_mfcc, X_test)\n",
    "\n",
    "    # Create segments from MFCCs\n",
    "    X_train, y_train = make_segments(X_train, y_train)\n",
    "    X_validation, y_validation = make_segments(X_test, y_test)\n",
    "\n",
    "    # Randomize training segments\n",
    "    X_train, _, y_train, _ = train_test_split(X_train, y_train, test_size=0)\n",
    "\n",
    "    # Train model\n",
    "    model = train_model(np.array(X_train), np.array(y_train), np.array(X_validation),np.array(y_validation))\n",
    "\n",
    "    # Make predictions on full X_test MFCCs\n",
    "    y_predicted = accuracy.predict_class_all(create_segmented_mfccs(X_test), model)\n",
    "\n",
    "    # Print statistics\n",
    "    print('Training samples:', train_count)\n",
    "    print('Testing samples:', test_count)\n",
    "    print('Accuracy to beat:', acc_to_beat)\n",
    "    print('Confusion matrix of total samples:\\n', np.sum(accuracy.confusion_matrix(y_predicted, y_test),axis=1))\n",
    "    print('Confusion matrix:\\n',accuracy.confusion_matrix(y_predicted, y_test))\n",
    "    print('Accuracy:', accuracy.get_accuracy(y_predicted,y_test))\n",
    "\n",
    "    # Save model\n",
    "    save_model(model, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0] = pool.map(get_wav, X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'afrikaans1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
